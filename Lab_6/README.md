## Описание лабораторной работы
Разработка модели для классификации текстовых комментариев на токсичные и нетоксичные с использованием предобученной языковой модели BERT. В работе применяются методы обработки естественного языка (NLP) и transfer learning.

## Исходные данные
Датасет содержит размеченные текстовые комментарии с меткой токсичности:

- text — текст комментария
- toxic — бинарная метка (1 — токсичный, 0 — нетоксичный)

## Выполненные этапы
### 1. Анализ и предобработка данных (EDA)
- Анализ распределения классов (токсичные/нетоксичные комментарии)
- Очистка текста:
    - Приведение к нижнему регистру
    - Удаление HTML-тегов и специальных символов
    - Лемматизация (приведение слов к нормальной форме)
    - Удаление стоп-слов (вспомогательных слов английского языка)
    - Проверка на пропуски и дубликаты

### 2. Подготовка данных для BERT
- Разделение данных на обучающую и валидационную выборки (80/20)
- Токенизация текста с использованием BertTokenizer
- Создание объектов Dataset и DataLoader для эффективной загрузки данных

### 3. Обучение модели
- Использование предобученной модели BertForSequenceClassification
- Настройка оптимизатора AdamW
- Обучение в течение 3 эпох с мониторингом потерь (loss)
- Оценка качества на валидационной выборке с помощью метрики F1-score

### 4. Оценка качества модели
- Анализ динамики обучения (loss и F1-score по эпохам)
- Построение матрицы ошибок для визуализации результатов классификации
- Проверка достижения целевого значения F1 ≥ 0.75
